{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import cvxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bound\n",
       "Id       \n",
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data = pd.read_csv('Ytr.csv', index_col=0)\n",
    "Y_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = pd.read_csv('Xtr.csv', index_col=0)  #header=None, sep=' '\n",
    "#X_train.drop(columns='Id', inplace=True)\n",
    "X_test_data = pd.read_csv('Xte.csv', index_col=0)     #header=None, sep=' '\n",
    "#X_test.drop(columns='Id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr_encoded (2000, 16384)\n",
      "max: 15.0, mean: 0.0057373046875\n",
      "non zeros: 32583265, zeros: 184735,\n",
      "ratio: 0.005637664794921875\n"
     ]
    }
   ],
   "source": [
    "WORD_LENTGH = 7\n",
    "base = {'A':0, 'C':1, 'T':2, 'G':3}\n",
    "index_size = 4**WORD_LENTGH\n",
    "\n",
    "\n",
    "def word_to_index(word):\n",
    "    index = 0\n",
    "    for i, carac in enumerate(word):\n",
    "        index += base[carac] * (4 ** i)\n",
    "    return index\n",
    "\n",
    "def encode_sequence(seq, word_len=WORD_LENTGH):\n",
    "    encoded = np.zeros(index_size)\n",
    "    for i in range(len(seq) - word_len):\n",
    "        word = seq[i:(i+word_len)]\n",
    "        index = word_to_index(word)\n",
    "        encoded[index] += 1\n",
    "    return encoded\n",
    "\n",
    "Xtr_encoded = X_train_data.seq.apply(encode_sequence)\n",
    "Xtr_encoded = np.stack(Xtr_encoded)\n",
    "\n",
    "print('Xtr_encoded', Xtr_encoded.shape)\n",
    "print('max: {}, mean: {}'.format(Xtr_encoded.max(), Xtr_encoded.mean()))\n",
    "print('non zeros: {}, zeros: {},'.format(np.sum(Xtr_encoded==0), np.sum(Xtr_encoded!=0)))\n",
    "print('ratio: {}'.format(np.sum(Xtr_encoded!=0)/(Xtr_encoded.shape[0]*Xtr_encoded.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xte_encoded (1000, 16384)\n",
      "max: 21.0, mean: 0.0057373046875\n",
      "non zeros: 16291596, zeros: 92404,\n",
      "ratio: 0.005639892578125\n"
     ]
    }
   ],
   "source": [
    "Xte_encoded = X_test_data.seq.apply(encode_sequence)\n",
    "Xte_encoded = np.stack(Xte_encoded)\n",
    "\n",
    "print('Xte_encoded', Xte_encoded.shape)\n",
    "print('max: {}, mean: {}'.format(Xte_encoded.max(), Xte_encoded.mean()))\n",
    "print('non zeros: {}, zeros: {},'.format(np.sum(Xte_encoded==0), np.sum(Xte_encoded!=0)))\n",
    "print('ratio: {}'.format(np.sum(Xte_encoded!=0)/(Xte_encoded.shape[0]*Xte_encoded.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data : Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = Xtr_encoded\n",
    "y = Y_train_data.Bound.values * 2 - 1\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM are using linear_kernel1 and rbf_kernel2\n",
    "\n",
    "def rbf_kernel1(gamma, **kwargs):\n",
    "    def f(x1, x2):\n",
    "        distance = np.linalg.norm(x1-x2)**2\n",
    "        return np.exp(-gamma*distance)\n",
    "    return f\n",
    "\n",
    "def linear_kernel1(**kwargs):\n",
    "    def f(x1, x2):\n",
    "        return x1 @ x2.T\n",
    "    return f\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    \n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "\n",
    "    return X1.dot(X2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeClassifier():\n",
    "    def __init__(self, lambd, sigma):     #: #, sigma):   # When using the linear kernel, sigma should be commented\n",
    "        self.lambd = lambd\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "\n",
    "        n,p = X.shape\n",
    "        I = np.eye(n)\n",
    "        A = rbf_kernel(X, self.X_train, sigma= self.sigma) + lambd*n*I\n",
    "        #A = linear_kernel(X, self.X_train) + lambd*n*I\n",
    "        self.alpha = np.linalg.solve(A, y)    \n",
    "\n",
    "    def predict(self, X):    \n",
    "        output = rbf_kernel(X, self.X_train, sigma= self.sigma) @ self.alpha\n",
    "        #output = linear_kernel(X, self.X_train) @ self.alpha\n",
    "        pred = np.sign(output)\n",
    "        return pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        accuracy = np.sum(pred == y) /len(y)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportVectorMachine(object):\n",
    "    def __init__(self, C=3, kernel= linear_kernel1, power=4, gamma= 2, coef= 2):\n",
    "        self.C = C\n",
    "        #self.kernel = kernel\n",
    "        self.power = power\n",
    "        self.gamma = gamma\n",
    "        self.coef = coef\n",
    "        self.lagr_multipliers = None\n",
    "        self.support_vectors = None\n",
    "        self.support_vector_labels = None\n",
    "        self.intercept = None\n",
    "        self.kernel = kernel(power = self.power, gamma= self.gamma, coef = self.coef)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = np.shape(X)\n",
    "        #Set gamma to 1/n_features by default\n",
    "        if not self.gamma:\n",
    "            self.gamma = 1/n_features\n",
    "        #Initialize kernel method with parameters\n",
    "        #self.kernel = self.kernel(power = self.power, gamma= self.gamma, coef = self.coef)\n",
    "        #Calculate kernel matrix\n",
    "        kernel_matrix = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range (n_samples):\n",
    "                kernel_matrix[i, j] = self.kernel(X[i], X[j])\n",
    "\n",
    "        # Define the quadratic optimization problem\n",
    "        P = cvxopt.matrix(np.outer(y, y) * kernel_matrix, tc='d')\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1, n_samples), tc='d')\n",
    "        b = cvxopt.matrix(0, tc='d')\n",
    "\n",
    "        if not self.C: #if its empty\n",
    "            G = cvxopt.matrix(np.identity(n_samples) * -1)\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            G_max = np.identity(n_samples) * -1\n",
    "            G_min = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((G_max, G_min)))\n",
    "            h_max = cvxopt.matrix(np.zeros(n_samples))\n",
    "            h_min = cvxopt.matrix(np.ones(n_samples) * self.C)\n",
    "            h = cvxopt.matrix(np.vstack((h_max, h_min)))\n",
    "\n",
    "        # Solve the quadratic optimization problem using cvxopt\n",
    "        minimization = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        lagr_mult = np.ravel(minimization['x'])\n",
    "\n",
    "        # Extract support vectors\n",
    "        # Get indexes of non-zero lagr. multipiers\n",
    "        idx = lagr_mult > 1e-11\n",
    "        # Get the corresponding lagr. multipliers\n",
    "        self.lagr_multipliers = lagr_mult[idx]\n",
    "        # Get the samples that will act as support vectors\n",
    "        self.support_vectors = X[idx]\n",
    "        # Get the corresponding labels\n",
    "        self.support_vector_labels = y[idx]\n",
    "\n",
    "        # Calculate intercept with first support vector\n",
    "        self.intercept = self.support_vector_labels[0]\n",
    "        for i in range(len(self.lagr_multipliers)):\n",
    "            self.intercept -= self.lagr_multipliers[i] * self.support_vector_labels[i] * self.kernel(self.support_vectors[i], self.support_vectors[0])\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        # Iterate through list of samples and make predictions\n",
    "        for sample in X:\n",
    "            prediction = 0\n",
    "            # Determine the label of the sample by the support vectors\n",
    "            for i in range(len(self.lagr_multipliers)):\n",
    "                prediction += self.lagr_multipliers[i] * self.support_vector_labels[i] * self.kernel(self.support_vectors[i], sample)\n",
    "            prediction += self.intercept\n",
    "            y_pred.append(np.sign(prediction))\n",
    "            \n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean(pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- SVM Classifier --\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.9475e+01 -4.3869e+03  1e+04  8e-01  5e-15\n",
      " 1:  5.8770e+01 -1.1343e+03  2e+03  8e-02  6e-15\n",
      " 2:  2.9046e+01 -2.5422e+02  3e+02  8e-03  6e-15\n",
      " 3: -4.3675e+00 -3.3102e+01  3e+01  2e-04  4e-15\n",
      " 4: -9.7997e+00 -1.2897e+01  3e+00  3e-06  2e-15\n",
      " 5: -1.0099e+01 -1.0581e+01  5e-01  5e-07  2e-15\n",
      " 6: -1.0148e+01 -1.0206e+01  6e-02  3e-08  2e-15\n",
      " 7: -1.0155e+01 -1.0158e+01  3e-03  1e-09  2e-15\n",
      " 8: -1.0156e+01 -1.0156e+01  9e-05  2e-11  2e-15\n",
      " 9: -1.0156e+01 -1.0156e+01  3e-06  3e-13  2e-15\n",
      "Optimal solution found.\n",
      "Train Accuracy scracht : 1.0\n",
      "Valid Accuracy scracht : 0.66\n"
     ]
    }
   ],
   "source": [
    "print (\"-- SVM Classifier --\")\n",
    "\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf = SupportVectorMachine(C=2.07 , kernel=linear_kernel1, gamma = 4.78e-03)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = clf.score(X_train, y_train)\n",
    "print (\"Train Accuracy scracht :\", train_accuracy)\n",
    "\n",
    "valid_accuracy = clf.score(X_val, y_val)\n",
    "print (\"Valid Accuracy scracht :\", valid_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train_accuracy = 0.7955555555555556, Val_accuracy = 0.655\n"
     ]
    }
   ],
   "source": [
    "lambd=3.26e-01\n",
    "sigma =11.61\n",
    "model = RidgeClassifier(lambd=lambd ,sigma=sigma) #sigma=sigma)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "#pred, final_scores = logistic_regression(X_train,  (y_train+1)/2, num_steps=100, learning_rate=0.05)\n",
    "train_acc = model.score(X_train, y_train)\n",
    "valid_acc = model.score(X_val, y_val)\n",
    "\n",
    "print(f' Train_accuracy = {train_acc}, Val_accuracy = {valid_acc}')\n",
    "\n",
    "#(final_scores).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random range of value \n",
    "def rand_range(begin, end):\n",
    "    return (end-begin)*np.random.rand() + begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validation(model, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    scores = []\n",
    "    train_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        acc_train = model.score(X_train, y_train)\n",
    "        accuracy  = model.score(X_test, y_test)\n",
    "        \n",
    "        #model.train(X_test, y_test)\n",
    "        #accuracy = model.score(X_train, y_train)\n",
    "        \n",
    "        train_scores.append(acc_train)\n",
    "        scores.append(accuracy)\n",
    "    \n",
    "    train_scores = np.array(train_scores)\n",
    "    scores = np.array(scores)\n",
    "    return scores, train_scores\n",
    "\n",
    "# scores = cross_validation(X_train, y_train)\n",
    "# scores\n",
    "# mean_acc = scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search with CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation 0n 5 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_saved = '' #run this to erase or init the history\n",
    "from IPython.display import clear_output\n",
    "    \n",
    "def prints(msg):\n",
    "    global print_saved\n",
    "    print_saved = msg + '\\n' + print_saved\n",
    "    clear_output(wait=True)\n",
    "    print(print_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9 | 3.26e-01  | 67.45%    | 95.79%   | [0.6575 0.685  0.685  0.6525 0.6925]\n",
      " 8 | 3.26e-01  | 68.25%    | 95.74%   | [0.685  0.695  0.6875 0.6775 0.6675]\n",
      " 7 | 3.26e-01  | 68.60%    | 95.77%   | [0.68   0.725  0.6775 0.6425 0.705 ]\n",
      " 6 | 3.26e-01  | 67.05%    | 95.84%   | [0.63   0.68   0.685  0.6675 0.69  ]\n",
      " 5 | 3.26e-01  | 68.90%    | 95.76%   | [0.69   0.68   0.7175 0.66   0.6975]\n",
      " 4 | 3.26e-01  | 66.70%    | 95.76%   | [0.6525 0.65   0.7    0.635  0.6975]\n",
      " 3 | 3.26e-01  | 67.15%    | 95.89%   | [0.6875 0.63   0.66   0.685  0.695 ]\n",
      " 2 | 3.26e-01  | 67.45%    | 95.84%   | [0.63   0.6875 0.6675 0.675  0.7125]\n",
      " 1 | 3.26e-01  | 68.20%    | 95.80%   | [0.685  0.6725 0.675  0.6875 0.69  ]\n",
      " 0 | 3.26e-01  | 67.45%    | 95.80%   | [0.675  0.66   0.675  0.66   0.7025]\n",
      "---|-------|--------|----------|------------|---------\n",
      " i | C     | gamma  | accuracy | mean_train | scores for all folds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prints(' i | C     | gamma  | accuracy | mean_train | scores for all folds')\n",
    "# prints('---|-------|--------|----------|------------|---------')\n",
    "\n",
    "# prints(' i |gamma   | accuracy | mean_train | scores for all folds')\n",
    "# prints('---|--------|----------|------------|---------')\n",
    "\n",
    "prints(' i | C     | gamma  | accuracy | mean_train | scores for all folds')\n",
    "prints('---|-------|--------|----------|------------|---------')\n",
    "#.........,..........,.......,...........,....................\n",
    "for i in range(10):\n",
    "    #C     = rand_range(0.1, 2)\n",
    "    #gamma = 10**rand_range(-3.5, -2.5)\n",
    "    #sigma = rand_range(2, 10)\n",
    "    lambd= 10**rand_range(-2, 1)\n",
    "    \n",
    "    #model = SupportVectorMachine(C=3, kernel= rbf_kernel, gamma= gamma, coef= 2)\n",
    "    model = RidgeClassifier(lambd) #, sigma)\n",
    "    \n",
    "    #scores, train_scores = cross_validation(model, X_train, y_train, cv=3)\n",
    "    scores, train_scores = cross_validation(model, X, y, cv=5)\n",
    "    mean_acc = scores.mean()\n",
    "    mean_train = train_scores.mean()\n",
    "    \n",
    "    #prints(f'{i:2d} | {C:2.2f} | {gamma:2.2e}  | {100*mean_acc:.2f}%    | {100*mean_train:.2f}%   | {scores}')     # for SVM with RBF kernel\n",
    "    #prints(f'{i:2d} | {C:2.2f} | {gamma:2.2e}  | {100*mean_acc:.2f}%    | {100*mean_train:.2f}%   | {scores}')     # for SVM with linear kernel\n",
    "    prints(f'{i:2d} | {lamda: 2.2e} | {sigma:2.2e}  | {100*mean_acc:.2f}%    | {100*mean_train:.2f}%   | {scores}') #for RidgeRegression with RBF kernel\n",
    "    #prints(f'{i:2d} | {lambd:2.2e}  | {100*mean_acc:.2f}%    | {100*mean_train:.2f}%   | {scores}')                # for RidgeRegression with linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_test, y_pred):\n",
    "    correct_pred = np.sum(y_test == y_pred)\n",
    "    total = len(y_test)\n",
    "    accuracy = correct_pred/ total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.76 | Valid 0.60\n"
     ]
    }
   ],
   "source": [
    "sigma = 9\n",
    "lambd = 3.26e-01\n",
    "#C=2.07   parameter of svm                    \n",
    "#gamma = 4.78e-03   svm              \n",
    "\n",
    "#model = RidgeClassifier(lambd)# with linear kernel\n",
    "#model = RidgeClassifier(lambd, sigma)# with linear kernel\n",
    "alpha = model.fit(X_train, y_train)\n",
    "\n",
    "#model = SupportVectorMachine(#C=C) #SVM with rbf_kernel\n",
    "#model = SupportVectorMachine(#C=C, gamma=gamma) #SVM with rbf_kernel\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy     = model.score(X_train, y_train)\n",
    "val_accuracy = model.score(X_val, y_val)\n",
    "\n",
    "print(f'Train {accuracy:.2f} | Valid {val_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.715 , 0.6875, 0.6425, 0.68  , 0.6625])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, fit_scores = cross_validation(model, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6775"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bound\n",
       "Id       \n",
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_prediction = model.predict(Xte_encoded)\n",
    "\n",
    "my_prediction[my_prediction== -1] = 0\n",
    "my_prediction= my_prediction.astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'Bound': my_prediction})\n",
    "submission.index.name = 'Id'\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 429 | ones: 571\n"
     ]
    }
   ],
   "source": [
    "# statistics on the prediction\n",
    "zeros = (my_prediction==0).sum()\n",
    "ones  = (my_prediction==1).sum()\n",
    "print(f'zeros: {zeros} | ones: {ones}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_71acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c kernel-methods-ammi-2020 -f 'submission_71acc.csv' -m 'length=6 model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
